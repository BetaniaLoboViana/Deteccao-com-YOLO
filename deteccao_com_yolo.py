# -*- coding: utf-8 -*-
"""Deteccao com yolo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-vuDVQDUuiLfW87hph_ofvbcVb5MdwFR
"""

# Instalar dependências
!pip install opencv-python
!pip install matplotlib
!pip install tensorflow
!pip install pycocotools
!apt-get install -y libopencv-dev libopencv-core-dev libopencv-imgproc-dev
!pip install opencv-python
!pip install -U git+https://github.com/ultralytics/yolov5.git
!pip install pycocotools

# Baixar o COCO dataset - Imagens de treinamento
!wget http://images.cocodataset.org/zips/train2017.zip
!unzip train2017.zip -d /content/coco

# Baixar as anotações do COCO
!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip
!unzip annotations_trainval2017.zip -d /content/coco

import os
import json
from shutil import copyfile
import cv2

# Função para converter COCO para YOLO
def coco_to_yolo(coco_annotation_file, images_dir, output_dir):
    # Carregar as anotações COCO
    with open(coco_annotation_file, 'r') as f:
        coco_data = json.load(f)

    # Dicionário de categorias (id -> nome)
    categories = {category['id']: category['name'] for category in coco_data['categories']}

    # Criar pasta de saída
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # Processar cada anotação
    for annotation in coco_data['annotations']:
        # Obter o nome da imagem e o caminho da imagem
        image_id = annotation['image_id']
        image_info = next(img for img in coco_data['images'] if img['id'] == image_id)
        image_filename = image_info['file_name']
        image_path = os.path.join(images_dir, image_filename)

        # Carregar a imagem para obter as dimensões
        img = cv2.imread(image_path)
        h, w, _ = img.shape

        # Calcular as coordenadas da caixa delimitadora no formato YOLO
        x_center = (annotation['bbox'][0] + annotation['bbox'][2] / 2) / w
        y_center = (annotation['bbox'][1] + annotation['bbox'][3] / 2) / h
        bbox_width = annotation['bbox'][2] / w
        bbox_height = annotation['bbox'][3] / h

        # Criar a linha para a anotação no formato YOLO
        category_id = annotation['category_id']
        class_name = categories[category_id]
        yolo_annotation = f"{class_name} {x_center} {y_center} {bbox_width} {bbox_height}\n"

        # Salvar as anotações em um arquivo de texto
        output_image_dir = os.path.join(output_dir, 'images')
        output_annotation_dir = os.path.join(output_dir, 'labels')

        if not os.path.exists(output_image_dir):
            os.makedirs(output_image_dir)
        if not os.path.exists(output_annotation_dir):
            os.makedirs(output_annotation_dir)

        # Copiar imagem para a pasta de saída
        copyfile(image_path, os.path.join(output_image_dir, image_filename))

        # Salvar anotação YOLO
        annotation_filename = image_filename.replace('.jpg', '.txt')
        with open(os.path.join(output_annotation_dir, annotation_filename), 'w') as f:
            f.write(yolo_annotation)

# Executar a conversão
coco_annotation_file = '/content/coco/annotations/instances_train2017.json'
images_dir = '/content/coco/train2017'
output_dir = '/content/coco/yolo_dataset'

coco_to_yolo(coco_annotation_file, images_dir, output_dir)

# Commented out IPython magic to ensure Python compatibility.
# Clonar o repositório YOLOv5
!git clone https://github.com/ultralytics/yolov5
# %cd yolov5

# Instalar dependências do YOLOv5
!pip install -U -r requirements.txt

# Preparar os dados e treinar
!python train.py --img 640 --batch 16 --epochs 10 --data /content/coco/yolo_dataset.yaml --cfg yolov5s.yaml

# Testar o modelo treinado
!python detect.py --weights runs/train/exp/weights/best.pt --img 640 --source /content/coco/test2017

